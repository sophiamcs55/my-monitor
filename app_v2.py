import streamlit as st
import pandas as pd
import plotly.express as px
import sqlite3
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from fpdf import FPDF
import base64
import google.generativeai as genai

# --- 0. é…ç½®ä¸åˆå§‹åŒ– ---
st.set_page_config(page_title="SharpShield Pro | é”å®åŠ›é˜²å¾¡ç³»ç»Ÿ", page_icon="ğŸ›¡ï¸", layout="wide")

# é…ç½® API KEY (è¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ Keyï¼Œæˆ–ä»ä¾§è¾¹æ è¾“å…¥)
# genai.configure(api_key="YOUR_API_KEY") 

# --- A. æ•°æ®åº“æŒä¹…åŒ–æ¨¡å— (Database Persistence) ---
def init_db():
    conn = sqlite3.connect('sharpshield.db')
    c = conn.cursor()
    # åˆ›å»ºè¡¨ï¼šå­˜å‚¨å†å²åˆ†æè®°å½•
    c.execute('''CREATE TABLE IF NOT EXISTS history
                 (id INTEGER PRIMARY KEY, 
                  timestamp TEXT, 
                  source TEXT, 
                  risk_score REAL, 
                  meta_narrative TEXT,
                  summary TEXT)''')
    conn.commit()
    return conn

def save_analysis(source, score, narrative, summary):
    conn = init_db()
    c = conn.cursor()
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    c.execute("INSERT INTO history (timestamp, source, risk_score, meta_narrative, summary) VALUES (?, ?, ?, ?, ?)",
              (ts, source, score, narrative, summary))
    conn.commit()
    conn.close()

def load_history():
    conn = init_db()
    df = pd.read_sql_query("SELECT * FROM history ORDER BY id DESC", conn)
    conn.close()
    return df

# --- B. å¤šæºé‡‡é›†è‡ªåŠ¨åŒ–æ¨¡å— (Multi-source Scraper) ---
def fetch_url_content(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ç§»é™¤æ— å…³æ ‡ç­¾
        for script in soup(["script", "style", "nav", "footer"]):
            script.extract()
        
        text = soup.get_text()
        # ç®€å•æ¸…æ´—ï¼šå»é™¤å¤šä½™ç©ºè¡Œ
        lines = (line.strip() for line in text.splitlines())
        clean_text = '\n'.join(chunk for chunk in lines if chunk)
        return clean_text[:3000] # é™åˆ¶é•¿åº¦ï¼Œé¿å… Token æº¢å‡º
    except Exception as e:
        return f"Error: {e}"

# --- æ¨¡æ‹Ÿ AI åˆ†æ (ä¸ºäº†è®©ä»£ç æ—  Key ä¹Ÿèƒ½è¿è¡Œæ¼”ç¤ºï¼Œè¿™é‡Œåšäº†ä¸€ä¸ªæ¨¡æ‹Ÿå™¨) ---
# çœŸå®ä½¿ç”¨æ—¶ï¼Œè¯·è§£å¼€ analyze_narrative_real çš„æ³¨é‡Šå¹¶é…ç½® Key
def mock_ai_analyze(text):
    # ç®€å•çš„å…³é”®è¯é€»è¾‘æ¨¡æ‹Ÿ AI
    score = 2.0
    narrative = "è‡ªç”±/ç¨‹åºå™äº‹"
    if "å¤å…´" in text or "ç»Ÿä¸€" in text or "è¡€æµ“äºæ°´" in text:
        score = 8.5
        narrative = "å¤å…´/ç§©åºå™äº‹ (Mainland Logic)"
    elif "ä¸»ä½“" in text or "é˜²å«" in text:
        score = 4.0
        narrative = "ç”Ÿå­˜/è‡ªä¸»å™äº‹ (Taiwan Logic)"
    
    return {
        "score": score,
        "narrative": narrative,
        "analysis": f"ç»æ‰«æï¼Œæ–‡æœ¬å«æœ‰é«˜é¢‘å…ƒå™äº‹å…³é”®è¯ã€‚é£é™©è¯„çº§ä¸º {score}/10ã€‚",
        "indicators": ["RE_2 (å¢ƒå¤–èµ„é‡‘)" if score > 7 else "æ— æ˜æ˜¾å¼‚å¸¸"]
    }

# --- C. UI è§†è§‰å‡çº§ä¸å¯¼å‡ºæ¨¡å— (Visuals & Export) ---
def create_pdf(analysis_data, text_content):
    pdf = FPDF()
    pdf.add_page()
    # å›  FPDF å¯¹ä¸­æ–‡æ”¯æŒè¾ƒç¹çï¼Œè¿™é‡Œæ¼”ç¤ºè‹±æ–‡æŠ¥å‘Šæˆ–éœ€åŠ è½½ä¸­æ–‡å­—ä½“
    # ä¸ºæ¼”ç¤ºæ–¹ä¾¿ï¼Œæˆ‘ä»¬ç”Ÿæˆç®€æ˜“ç‰ˆ
    pdf.set_font("Arial", size=12)
    pdf.cell(200, 10, txt="SharpShield Intelligence Report", ln=True, align='C')
    pdf.ln(10)
    pdf.cell(200, 10, txt=f"Date: {datetime.now().strftime('%Y-%m-%d')}", ln=True)
    pdf.cell(200, 10, txt=f"Risk Score: {analysis_data['score']}/10", ln=True)
    pdf.cell(200, 10, txt=f"Meta-Narrative: {analysis_data['narrative']}", ln=True)
    pdf.ln(10)
    pdf.multi_cell(0, 10, txt=f"Analysis Summary:\n{analysis_data['analysis']}")
    
    return pdf.output(dest='S').encode('latin-1')

# --- ä¸»ç¨‹åºé€»è¾‘ ---

# ä¾§è¾¹æ ï¼šAPI è®¾ç½®ä¸å†å²æ•°æ®
with st.sidebar:
    st.title("ğŸ›¡ï¸ æ§åˆ¶ä¸­å¿ƒ")
    api_key = st.text_input("è¾“å…¥ Gemini API Key (å¯é€‰)", type="password")
    if api_key:
        genai.configure(api_key=api_key)
    
    st.divider()
    st.subheader("ğŸ“Š å†å²è¶‹åŠ¿åº“ (DB)")
    history_df = load_history()
    if not history_df.empty:
        st.dataframe(history_df[['timestamp', 'risk_score', 'meta_narrative']], height=200)
        # ç®€å•è¶‹åŠ¿å›¾
        st.line_chart(history_df.set_index('timestamp')['risk_score'])
    else:
        st.info("æš‚æ— å†å²æ•°æ®ï¼Œè¯·æ‰§è¡Œä¸€æ¬¡åˆ†æã€‚")

# ä¸»ç•Œé¢
st.title("SharpShield Pro: å…¨åŸŸå½±å“åŠ›ç›‘æµ‹ç»ˆç«¯")
st.markdown("---")

# è¾“å…¥åŒºï¼šæ”¯æŒ æ–‡æœ¬ æˆ– URL
col_input1, col_input2 = st.columns([3, 1])
with col_input1:
    input_type = st.radio("æ•°æ®æºé€‰æ‹©", ["ğŸ“ æ‰‹åŠ¨æ–‡æœ¬è¾“å…¥", "ğŸŒ URL è‡ªåŠ¨æŠ“å–"], horizontal=True)

target_text = ""
source_label = "Manual Input"

if input_type == "ğŸ“ æ‰‹åŠ¨æ–‡æœ¬è¾“å…¥":
    target_text = st.text_area("è¾“å…¥å¾…æµ‹æ–‡æœ¬", height=150, placeholder="ç²˜è´´å®«åº™å…¬å‘Šã€æ–°é—»æŠ¥é“æˆ–ç¤¾äº¤åª’ä½“è´´æ–‡...")
else:
    url = st.text_input("è¾“å…¥ç›®æ ‡ç½‘å€ (URL)", placeholder="https://news.example.com/article/123")
    if url and st.button("ğŸ•·ï¸ å¼€å§‹æŠ“å–"):
        with st.spinner("æ­£åœ¨æ´¾é£çˆ¬è™«..."):
            fetched = fetch_url_content(url)
            if "Error" not in fetched:
                st.success("æŠ“å–æˆåŠŸï¼")
                target_text = fetched
                st.text_area("æŠ“å–å†…å®¹é¢„è§ˆ", value=fetched, height=100)
                source_label = url
            else:
                st.error(fetched)

# åˆ†ææ‰§è¡ŒåŒº
if st.button("ğŸš€ å¯åŠ¨å…¨ç»´æ‰«æ (Analyze)"):
    if not target_text:
        st.warning("è¯·è¾“å…¥æ–‡æœ¬æˆ–æŠ“å–æœ‰æ•ˆå†…å®¹ã€‚")
    else:
        with st.spinner("æ­£åœ¨è¿›è¡Œå…ƒå™äº‹è§£æ„ä¸æŒ‡æ ‡åŒ¹é…..."):
            # 1. è°ƒç”¨ AI (å¦‚æœæ²¡ Key åˆ™ç”¨æ¨¡æ‹Ÿå™¨)
            result = mock_ai_analyze(target_text)
            
            # 2. å­˜å…¥æ•°æ®åº“ (Step A å®ç°)
            save_analysis(source_label, result['score'], result['narrative'], result['analysis'])
            
            # 3. ç»“æœå±•ç¤º (Step C è§†è§‰å‡çº§)
            c1, c2, c3 = st.columns(3)
            with c1:
                st.metric("ç©¿åˆºé£é™©è¯„åˆ†", f"{result['score']} / 10", delta_color="inverse")
            with c2:
                st.info(f"ğŸ›¡ï¸ æ ¸å¿ƒå…ƒå™äº‹åˆ¤å®š:\n**{result['narrative']}**")
            with c3:
                st.warning(f"âš ï¸ å‘½ä¸­æŒ‡æ ‡:\n{', '.join(result['indicators'])}")
            
            # 4. ç‚«é…·é›·è¾¾å›¾
            st.subheader("é›·è¾¾ç‰¹å¾å›¾è°±")
            # æ¨¡æ‹Ÿå…­ç»´æ•°æ®åˆ†å¸ƒ
            radar_data = pd.DataFrame(dict(
                r=[result['score'], result['score']*0.8, result['score']*0.6, 5, 4, 7],
                theta=['å®—æ•™æ¸—é€', 'æŠ€æœ¯é”å®š', 'æ”¿æ²»ä¿˜è·', 'å­¦æœ¯å¹²æ‰°', 'ç»æµä¾èµ–', 'åª’ä½“æ“å¼„']
            ))
            fig = px.line_polar(radar_data, r='r', theta='theta', line_close=True, range_r=[0,10])
            fig.update_traces(fill='toself', line_color='#ff2b2b' if result['score']>7 else '#00cc96')
            fig.update_layout(polar=dict(bgcolor="#0e1117"))
            st.plotly_chart(fig, use_container_width=True)

            # 5. å¯¼å‡ºæŠ¥å‘Š (Step C å¯¼å‡ºåŠŸèƒ½)
            pdf_bytes = create_pdf(result, target_text)
            st.download_button(
                label="ğŸ“„ å¯¼å‡º PDF æˆ˜ç•¥ç®€æŠ¥",
                data=base64.b64decode(pdf_bytes),
                file_name="sharpshield_report.pdf",
                mime="application/pdf"
            )

            st.success("åˆ†æå®Œæˆï¼Œæ•°æ®å·²å½’æ¡£è‡³æœ¬åœ°æ•°æ®åº“ã€‚")

            st.rerun() # åˆ·æ–°ä»¥æ›´æ–°ä¾§è¾¹æ å†å²è®°å½•
