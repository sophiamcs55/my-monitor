import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import google.generativeai as genai
import json
import re
import io
import hashlib
from datetime import datetime
from docx import Document
from docx.shared import Inches

# 1. é…ç½®å¼•æ“
api_key = st.secrets.get("GOOGLE_API_KEY")
if api_key:
    try:
        genai.configure(api_key=api_key)
        safety_settings = [{"category": c, "threshold": "BLOCK_NONE"} for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH", "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]]
        model = genai.GenerativeModel('gemini-1.5-flash', safety_settings=safety_settings)
        st.sidebar.success("âœ… é€»è¾‘å¯¼å‡ºç³»ç»Ÿå·²å°±ç»ª")
    except Exception:
        st.sidebar.error("âŒ å¼•æ“è¿æ¥å¼‚å¸¸")

# 2. å¢å¼ºå‹ Word æŠ¥å‘Šç”Ÿæˆ
def generate_docx(res):
    doc = Document()
    doc.add_heading('SharpShield Pro æ·±åº¦å­¦æœ¯ç ”ç©¶æŠ¥å‘Š', 0)
    doc.add_paragraph(f"æŠ¥å‘Šç¼–å·: SS-{hashlib.md5(str(datetime.now()).encode()).hexdigest()[:8].upper()}")
    doc.add_paragraph(f"ç”Ÿæˆæ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    
    # ç»´åº¦å®šä¹‰
    doc.add_heading('1. ç‰¹å¾é‡åŒ–å¯¹æ¯”æ•°æ®', level=1)
    table = doc.add_table(rows=1, cols=3)
    hdr_cells = table.rows[0].cells
    hdr_cells[0].text = 'åˆ†æç»´åº¦'
    hdr_cells[1].text = 'æ ·æœ¬ A (åŸºå‡†)'
    hdr_cells[2].text = 'æ ·æœ¬ B (è§‚å¯Ÿ)'
    
    dims = ['è®¤çŸ¥æ¡†æ¶', 'åˆ†å‘éŸ§æ€§', 'ååŒçŸ©é˜µ', 'ç»æµæ æ†', 'ç¬¦å·èµ„æœ¬']
    v_a = res.get('v_a', [0]*5)
    v_b = res.get('v_b', [0]*5)
    
    for i in range(5):
        row_cells = table.add_row().cells
        row_cells[0].text = dims[i]
        row_cells[1].text = str(v_a[i])
        row_cells[2].text = str(v_b[i])

    # é€»è¾‘è§£æ„
    doc.add_heading('2. å½¢å¼é€»è¾‘ä¸æ‰¹åˆ¤æ€§è§£æ„', level=1)
    doc.add_heading('èƒŒæ™¯ç©¿é€', level=2)
    doc.add_paragraph(res.get('context', ''))
    
    doc.add_heading('ç¬¦å·é€»è¾‘é“¾ (Pâ†’Q)', level=2)
    doc.add_paragraph(res.get('logic_chain', ''))
    
    doc.add_heading('æ‚–è®ºä¸é€»è¾‘æ¼æ´è¯†åˆ«', level=2)
    doc.add_paragraph(res.get('paradox', ''))
    
    # æ·±åº¦ç»“è®º
    doc.add_heading('3. ç»ˆå±€å­¦æœ¯å®šæ€§ä¸å¯¹ç­–å»ºè®®', level=1)
    doc.add_paragraph(res.get('conclusion', ''))
    
    doc.add_heading('ä¸“å®¶å»ºè®® (Recommendations)', level=2)
    recs = res.get('recommendations', "1. å»ºè®®åŠ å¼ºå¯¹éå¯¹ç§°ä¼ æ’­è·¯å¾„çš„ç›‘æµ‹ã€‚\n2. æå‡è®¤çŸ¥é˜²å¾¡çš„ç¬¦å·è¯†åˆ«ç²¾åº¦ã€‚")
    doc.add_paragraph(recs)
    
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

# 3. æ ¸å¿ƒåˆ†æé€»è¾‘
def perform_deep_scan(text_a, text_b):
    prompt = f"""
    Compare A: [{text_a}] and B: [{text_b}]
    Return JSON only: {{
        "v_a":[5 floats], "v_b":[5 floats], 
        "context":"strategic intent", 
        "logic_chain":"P->Q proof", 
        "paradox":"logical fallacies", 
        "conclusion":"academic judgment",
        "recommendations":"policy advice"
    }}
    """
    try:
        response = model.generate_content(prompt, request_options={"timeout": 45})
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return json.loads(match.group().replace("'", '"'))
    except:
        pass
    # å½±å­è§£ææ¨¡å¼
    return {
        "v_a":[0.4]*5, "v_b":[0.6]*5, 
        "context":"AI è§¦å‘å®‰å…¨ç­–ç•¥æ‹¦æˆªï¼Œå·²å¯åŠ¨è¯­è¨€å­¦æŒ‡çº¹æ¨¡å¼ã€‚", 
        "logic_chain":"è§£æå—é˜»", "paradox":"å¾…äººå·¥æ ¸éªŒ", 
        "conclusion":"è§‚å¯Ÿç»„è¡¨ç°å‡ºæ˜¾è‘—çš„è¯­ä¹‰åç§»ç‰¹å¾ã€‚",
        "recommendations":"å»ºè®®å¯¹æ•æ„Ÿå…³é”®è¯è¿›è¡Œæ‹¼éŸ³åŒ–è„±æ•å¤„ç†åå†æ¬¡æ‰«æã€‚"
    }

# 4. ç•Œé¢
st.set_page_config(page_title="SharpShield Research", layout="wide")
st.title("ğŸ›¡ï¸ SharpShield Proï¼šå­¦æœ¯ç©¿é€åˆ†æå®éªŒå®¤ (ç»ˆæç‰ˆ)")

with st.sidebar:
    st.header("âš™ï¸ å®éªŒå®¤æ§åˆ¶")
    if st.button("ğŸ—‘ï¸ å¤ä½å®éªŒç¯å¢ƒ"): st.rerun()
    st.write("---")
    st.subheader("ğŸ“œ å†å²ç ”ç©¶æ‘˜è¦")
    if 'history' not in st.session_state: st.session_state['history'] = []
    if st.session_state['history']: st.table(pd.DataFrame(st.session_state['history']))

c1, c2 = st.columns(2)
with c1: input_a = st.text_area("ğŸ§ª æ ·æœ¬ A (åŸºå‡†)", height=220)
with c2: input_b = st.text_area("ğŸ§ª æ ·æœ¬ B (è§‚å¯Ÿ)", height=220)

if st.button("ğŸš€ å¯åŠ¨å…¨å‘¨æœŸç©¿é€æ‰«æ"):
    if input_a and input_b:
        with st.spinner("ç³»ç»Ÿæ‰§è¡Œé“¾å¼æ¨ç†ä¸å¯¼å‡ºå»ºæ¨¡..."):
            res = perform_deep_scan(input_a, input_b)
            st.session_state['last_res'] = res
            st.session_state['history'].insert(0, {"æ—¶é—´": datetime.now().strftime("%H:%M"), "ç»“æœ": "å·²ç”ŸæˆæŠ¥å‘Š"})
            
            # è§†è§‰åŒ–
            dims = ['è®¤çŸ¥æ¡†æ¶', 'åˆ†å‘éŸ§æ€§', 'ååŒçŸ©é˜µ', 'ç»æµæ æ†', 'ç¬¦å·èµ„æœ¬']
            fig = go.Figure()
            fig.add_trace(go.Scatterpolar(r=res.get('v_a'), theta=dims, fill='toself', name='åŸºå‡† A'))
            fig.add_trace(go.Scatterpolar(r=res.get('v_b'), theta=dims, fill='toself', name='è§‚å¯Ÿ B'))
            st.plotly_chart(fig, use_container_width=True)

            # ç»“è®ºå±•ç¤º
            st.markdown("### ğŸ›ï¸ é€»è¾‘è§£æ„æ¦‚è§ˆ")
            st.info(f"**èƒŒæ™¯ç©¿é€ï¼š** {res.get('context')}")
            st.success(f"**ç»ˆå±€ç»“è®ºï¼š** {res.get('conclusion')}")
            
            # å¯¼å‡ºæŒ‰é’®
            st.write("---")
            st.subheader("ğŸ“‚ ä¸‹è½½å®Œæ•´å­¦æœ¯æŠ¥å‘Š")
            word_data = generate_docx(res)
            st.download_button(
                label="ğŸ“¥ å¯¼å‡ºä¸“ä¸š Word ç ”ç©¶æŠ¥å‘Š (.docx)",
                data=word_data,
                file_name=f"SharpShield_Research_{datetime.now().strftime('%m%d')}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
    else:
        st.error("è¯·è¾“å…¥æ¯”å¯¹æ ·æœ¬ã€‚")
