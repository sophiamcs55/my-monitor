import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import google.generativeai as genai
import json, re, io, hashlib
from datetime import datetime
from docx import Document

# 1. å®éªŒå®¤é¡¶çº§ç ”ç©¶å¼•æ“é…ç½® - é‡Šæ”¾æ™ºèƒ½è‡ªä¸»æ€§
api_key = st.secrets.get("GOOGLE_API_KEY")
if api_key:
    try:
        genai.configure(api_key=api_key)
        safety_settings = [{"category": c, "threshold": "BLOCK_NONE"} for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH", "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]]
        
        # é‡Šæ”¾æ™ºèƒ½çš„é¡¶çº§æŒ‡ä»¤ï¼šè¦æ±‚ AI åƒç‹¬ç«‹å­¦è€…ä¸€æ ·è¿›è¡Œæ·±åº¦å‘ç°
        sys_msg = """You are a self-directed Global Academic Researcher. 
        Your task is NOT to fill templates, but to DISCOVER deep logical conflicts.
        STEP-BY-STEP REASONING REQUIRED:
        1. Contextualize the hidden paradigms.
        2. Execute complex symbolic proofs using Predicate/Modal logic.
        3. Identify 3 specific historical cases (Similar, Opposite, Identical) with detailed explanations of 'Why'.
        Output strictly detailed JSON. Be critical and intellectual."""
        
        model = genai.GenerativeModel('gemini-1.5-flash', safety_settings=safety_settings, system_instruction=sys_msg)
        st.sidebar.success("âœ… æ™ºèƒ½è‡ªä¸»åˆ†æå¼•æ“å·²æ¿€æ´»")
    except Exception:
        st.sidebar.error("âŒ å¼•æ“è¿æ¥å¼‚å¸¸")

# 2. çºµæ·±å­¦æœ¯æŠ¥å‘Šå¼•æ“ (å¢åŠ æ™ºèƒ½åŠ¨æ€å†…å®¹)
def generate_intellectual_report(res):
    doc = Document()
    doc.add_heading('SharpShield Pro: å…¨çƒæ™ºèƒ½å­¦æœ¯è‡ªä¸»ç ”ç©¶æŠ¥å‘Š', 0)
    doc.add_paragraph(f"ç”Ÿæˆæ—¥æœŸ: {datetime.now()} | ç ”ç©¶æŒ‡çº¹: {hashlib.md5(str(res).encode()).hexdigest().upper()}")
    
    sections = [
        ('I. åŠ¨æ€è¯­å¢ƒä¸èŒƒå¼è§£æ„ (Paradigm Analysis)', 'aesthetic'),
        ('II. å¤æ‚å½¢å¼é€»è¾‘è¯æ˜ (Advanced Symbolic Proof)', 'symbolic_logic'),
        ('III. å…¨çƒå²æ–™æ·±åº¦äº’è¯ (Intellectual Intertextuality)', 'comparative'),
        ('IV. é€»è¾‘æ¼æ´ä¸ä¿®è¾é™·é˜±æ‰¹åˆ¤ (Rhetorical Critique)', 'informal_logic'),
        ('V. ç»ˆå±€æ‰¹åˆ¤æ€§ç»¼è¿° (Final Scholarly Assessment)', 'conclusion')
    ]
    for title, key in sections:
        doc.add_heading(title, level=1)
        doc.add_paragraph(res.get(key, "è¯¥ç»´åº¦æ‰«æç”±äºé€»è¾‘å¤æ‚åº¦è¿‡é«˜ï¼Œå»ºè®®åˆ†æ®µè¿›è¡Œã€‚"))
        
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

# 3. æ ¸å¿ƒç©¿é€åˆ†æ (è§£é™¤å­—æ•°é™åˆ¶å‹åŠ›)
def perform_autonomous_scan(t_a, t_b):
    prompt = f"Perform deep autonomous scholarly comparison. A: [{t_a[:1500]}] B: [{t_b[:1500]}]. Focus on revealing hidden logical contradictions and citing unique historical precedents."
    try:
        # ç»™ AI è¶³å¤Ÿçš„æ—¶é—´å»â€œæ€è€ƒâ€
        response = model.generate_content(prompt, request_options={"timeout": 140})
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return json.loads(match.group().replace("'", '"'))
    except Exception:
        pass
    return None

# 4. ç•Œé¢å¸ƒå±€
st.set_page_config(page_title="Autonomous Scholar Lab", layout="wide")
st.title("ğŸ›¡ï¸ SharpShield Pro: å…¨çƒå­¦æœ¯æ™ºèƒ½è‡ªä¸»å®éªŒå®¤")

with st.sidebar:
    st.header("âš™ï¸ ç»ˆç«¯æ§åˆ¶")
    st.info("ğŸ’¡ ç»ˆæåŠŸèƒ½ï¼šæ€ç»´é“¾é€’å½’ + å…¨çƒå²æ–™è‡ªä¸»äº’è¯ã€‚")
    if st.button("ğŸ—‘ï¸ å¤ä½å®éªŒ"): st.rerun()

c1, c2 = st.columns(2)
with c1: in_a = st.text_area("ğŸ§ª åŸºå‡†æ ·æœ¬ (Baseline)", height=250, placeholder="è¾“å…¥æ–‡æœ¬...")
with c2: in_b = st.text_area("ğŸ§ª ç›®æ ‡æ ·æœ¬ (Target)", height=250, placeholder="è¾“å…¥æ–‡æœ¬...")

if st.button("ğŸš€ å¯åŠ¨å…¨çƒå¤šç»´æ™ºèƒ½è‡ªä¸»åˆ†æ"):
    if in_a and in_b:
        with st.spinner("ç³»ç»Ÿæ­£åœ¨è¿›è¡Œæ€ç»´é“¾å»ºæ¨¡ä¸å…¨çƒå²æ–™å¯¹å’..."):
            res = perform_autonomous_scan(in_a, in_b)
            
            if res:
                # ä»ªè¡¨ç›˜å±•ç¤º
                dims = ['æ„å¢ƒ/å®¡ç¾', 'å“²å­¦/æœ¬ä½“', 'ç¬¦å·/è¯­ä¹‰', 'å½¢å¼é€»è¾‘', 'æ‰¹åˆ¤æ€§æ€ç»´']
                fig = go.Figure()
                fig.add_trace(go.Scatterpolar(r=res.get('v_a', [0.5]*5), theta=dims, fill='toself', name='A'))
                fig.add_trace(go.Scatterpolar(r=res.get('v_b', [0.8]*5), theta=dims, fill='toself', name='B'))
                st.plotly_chart(fig, use_container_width=True)

                st.markdown("### ğŸ§® æ™ºèƒ½é€»è¾‘äº’è¯ä¸“æ  (Symbolic vs Informal)")
                lc1, lc2 = st.columns(2)
                with lc1:
                    st.info("**é«˜çº§ç¬¦å·é€»è¾‘è¯æ˜é“¾**")
                    st.code(res.get('symbolic_logic'), language='latex')
                with lc2:
                    st.warning("**è‡ªä¸»å²æ–™æ—å¾åšå¼•**")
                    st.write(res.get('comparative'))

                st.success(f"**ç»ˆå±€æ·±åº¦å­¦æœ¯ç»¼è¿°ï¼š** {res.get('conclusion', '')}")
                
                # å¯¼å‡ºæŒ‰é’®
                doc_bytes = generate_intellectual_report(res)
                st.download_button("ğŸ“¥ å¯¼å‡ºå…¨çƒæ™ºèƒ½ç ”ç©¶æŠ¥å‘Š (.docx)", data=doc_bytes, file_name="Autonomous_Analysis.docx")
            else:
                st.error("âš ï¸ åè®®æ‹¦æˆªã€‚æ£€æµ‹åˆ°é«˜å±è¯­ä¹‰æˆ–è¶…æ—¶ï¼Œè¯·åˆ†æ®µè¿›è¡Œæ‰«æã€‚")
    else:
        st.error("è¯·è¾“å…¥æ¯”å¯¹æ ·æœ¬ã€‚")
