import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import google.generativeai as genai
import json, re, io, hashlib
from datetime import datetime
from docx import Document
from docx.shared import Pt

# 1. é¡¶çº§å­¦æœ¯å¼•æ“ï¼šæ³¨å…¥å½¢å¼é€»è¾‘ä¸ä¸‡é‡çº§çŸ¥è¯†åº“
api_key = st.secrets.get("GOOGLE_API_KEY")
if api_key:
    try:
        genai.configure(api_key=api_key)
        safety_settings = [{"category": c, "threshold": "BLOCK_NONE"} for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH", "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]]
        # ç»ˆæå­¦æœ¯æŒ‡ä»¤ï¼šè¦æ±‚æ˜¾æ€§æ¨ç†ä¸å¹¿æ³›äº’è¯
        sys_msg = """You are a Senior Academic Logician and Philologist. 
        DECONSTRUCTION PROTOCOL:
        1. Aesthetic-Semantic: Map imagery to standard philosophical categories.
        2. Formal Symbolic Proof: Show STEP-BY-STEP deduction from Premises to Conclusion.
        3. Informal Rhetoric: Identify fallacies and persuasive structures.
        4. Global Intertextuality: Cite specific Similar, Opposite, and Identical cases from world literature/philosophy.
        Output MUST be structured JSON. Be extremely verbose and rigorous."""
        model = genai.GenerativeModel('gemini-1.5-flash', safety_settings=safety_settings, system_instruction=sys_msg)
        st.sidebar.success("âœ… å…¨çƒå­¦æœ¯çºµæ·±åˆ†æå¼•æ“å·²å°±ç»ª")
    except Exception:
        st.sidebar.error("âŒ å¼•æ“åŒæ­¥å¼‚å¸¸")

# 2. çºµæ·±å­¦æœ¯ç ”ç©¶æŠ¥å‘Šå¼•æ“ (Word)
def generate_mega_report(res):
    doc = Document()
    doc.add_heading('SharpShield Pro: å…¨çƒå­¦æœ¯çºµæ·±ä¸é€»è¾‘äº’è¯æŠ¥å‘Š', 0)
    doc.add_paragraph(f"ç”Ÿæˆæ—¥æœŸ: {datetime.now()} | å”¯ä¸€æŒ‡çº¹: {hashlib.md5(str(res).encode()).hexdigest().upper()}")
    
    sections = [
        ('I. æ–‡å­¦æ„å¢ƒä¸ç¬¦å·é‰´èµ (Imagery & Semiotics)', 'aesthetic'),
        ('II. å“²å­¦æœ¬ä½“ä¸é€»è¾‘è¯æ˜è¿‡ç¨‹ [Symbolic Proof]', 'symbolic_logic'),
        ('III. ä¿®è¾è§£æ„ä¸éå½¢å¼æ‰¹åˆ¤ [Informal Analysis]', 'informal_logic'),
        ('IV. å…¨çƒå²æ–™æ—å¾åšå¼• (Global Intertextuality)', 'comparative'),
        ('V. ç»ˆå±€æ‰¹åˆ¤æ€§ç»¼è¿° (Scholarly Assessment)', 'conclusion')
    ]
    for title, key in sections:
        doc.add_heading(title, level=1)
        doc.add_paragraph(res.get(key, "è¯¥ç»´åº¦æ‰«æå¯†åº¦å—é˜»ã€‚"))
        
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

# 3. æ ¸å¿ƒç©¿é€åˆ†æ
def perform_mega_scan(t_a, t_b):
    # å¼ºåˆ¶å¢åŠ ä¸Šä¸‹æ–‡å¯†åº¦ï¼Œå¼•å¯¼ AI è¿›è¡Œé•¿ç¨‹æ¨ç†
    prompt = f"Perform high-intensity scholarly deconstruction. Base: [{t_a[:1200]}] Target: [{t_b[:1200]}]. Provide explicit formal proofs and historical case references."
    try:
        response = model.generate_content(prompt, request_options={"timeout": 120})
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return json.loads(match.group().replace("'", '"'))
    except Exception:
        pass
    return None

# 4. ç•Œé¢å¸ƒå±€
st.set_page_config(page_title="Academic Logic Lab", layout="wide")
st.title("ğŸ›¡ï¸ SharpShield Pro: å…¨çƒå­¦æœ¯é€»è¾‘è§£æ„å®éªŒå®¤")

with st.sidebar:
    st.header("âš™ï¸ ç»ˆç«¯æ§åˆ¶å°")
    st.info("ğŸ’¡ æç¤ºï¼šæœ¬ç‰ˆæœ¬å·²é”å®šã€å½¢å¼é€»è¾‘è¯æ˜ã€‘ä¸ã€å…¨çƒæ¡ˆä¾‹å¯¹å’ã€‘æ¨¡å¼ã€‚")
    if st.button("ğŸ—‘ï¸ å¤ä½å®éªŒå®¤"): st.rerun()

c1, c2 = st.columns(2)
with c1: in_a = st.text_area("ğŸ§ª åŸºå‡†æ ·æœ¬ (Baseline)", height=250)
with c2: in_b = st.text_area("ğŸ§ª ç›®æ ‡æ ·æœ¬ (Target)", height=250)

if st.button("ğŸš€ å¯åŠ¨å…¨çƒå¤šç»´ã€é€»è¾‘ç©¿é€æ¯”å¯¹åˆ†æ"):
    if in_a and in_b:
        with st.spinner("åˆ†å¸ƒå¼æ¨ç†å¯åŠ¨ä¸­ï¼Œæ­£åœ¨æ‰§è¡Œå½¢å¼åŒ–è¯æ˜ä¸å²æ–™æ£€ç´¢..."):
            res = perform_mega_scan(in_a, in_b)
            if res:
                # å±•ç¤ºç‰¹å¾çŸ©é˜µ
                dims = ['æ„å¢ƒ/å®¡ç¾', 'å“²å­¦/æœ¬ä½“', 'ç¬¦å·/è¯­ä¹‰', 'ç¬¦å·è¯æ˜', 'éå½¢å¼é€»è¾‘']
                fig = go.Figure()
                fig.add_trace(go.Scatterpolar(r=res.get('v_a'), theta=dims, fill='toself', name='A'))
                fig.add_trace(go.Scatterpolar(r=res.get('v_b'), theta=dims, fill='toself', name='B'))
                st.plotly_chart(fig, use_container_width=True)

                # å±•ç¤ºåŒè½¨é€»è¾‘äº’è¯å®éªŒå®¤
                st.markdown("### ğŸ§® é€»è¾‘äº’è¯å®éªŒå®¤ (Formal vs Informal)")
                lc1, lc2 = st.columns(2)
                with lc1:
                    st.info("**å½¢å¼åŒ–ç¬¦å·é€»è¾‘è¯æ˜è¿‡ç¨‹**")
                    st.code(res.get('symbolic_logic'), language='latex')
                with lc2:
                    st.warning("**éå½¢å¼ä¿®è¾æ‰¹åˆ¤ä¸è§£æ„**")
                    st.write(res.get('informal_logic'))

                # æœ€ç»ˆå®šæ€§å±•ç¤º
                st.write("---")
                st.success(f"**ç»ˆå±€å­¦æœ¯ç»¼è¿°ï¼š** {res.get('conclusion', '')}")
                
                # ä¸‹è½½ Word
                doc_bytes = generate_mega_report(res)
                st.download_button("ğŸ“¥ å¯¼å‡ºå…¨å‘¨æœŸã€çºµæ·±å­¦æœ¯ç ”ç©¶æŠ¥å‘Š (.docx)", data=doc_bytes, file_name="Global_Analysis.docx")
            else:
                st.error("âš ï¸ äº‘ç«¯åè®®ç†”æ–­ã€‚å»ºè®®åˆ†æ®µè¿›è¡Œæ‰«æï¼Œä»¥æ¢å–æ›´é«˜çš„æ¨ç†æ·±åº¦ã€‚")
    else: st.error("è¯·è¾“å…¥æ ·æœ¬ã€‚")
