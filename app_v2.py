import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import google.generativeai as genai
import json, re, io, hashlib
from datetime import datetime
from docx import Document

# 1. é¡¶çº§å­¦æœ¯å¼•æ“é…ç½® - å¼ºåˆ¶æ€§é€»è¾‘è§£æ„æ¨¡å¼
api_key = st.secrets.get("GOOGLE_API_KEY")
if api_key:
    try:
        genai.configure(api_key=api_key)
        # æ¿€æ´»æé™ç©¿é€å®‰å…¨ç­–ç•¥
        safety_settings = [{"category": c, "threshold": "BLOCK_NONE"} for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH", "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]]
        
        # é”å®š AI ä¸ºçº¯ç²¹çš„ç¬¦å·é€»è¾‘åˆ†æä»ª
        sys_msg = """You are the 'Universal Scholarly Symbolic Prover'. 
        MANDATORY: 
        1. Quantify imagery and philosophical depth into 5D vectors.
        2. Provide FORMAL Symbolic Proof (e.g., P^Q->R) and INFORMAL Rhetorical Critique.
        3. Cross-reference with global historical cases (Similar/Opposite/Identical).
        Output ONLY valid JSON. Avoid narrative fluff."""
        
        model = genai.GenerativeModel('gemini-1.5-flash', safety_settings=safety_settings, system_instruction=sys_msg)
        st.sidebar.success("âœ… é€»è¾‘å…¨æ¯åˆ†æéš§é“å·²æŒ‚è½½")
    except Exception:
        st.sidebar.error("âŒ å¼•æ“è¿æ¥å—é™")

# 2. çºµæ·±å­¦æœ¯ç ”ç©¶æŠ¥å‘Šå¼•æ“ (Word)
def generate_ultimate_report(res):
    doc = Document()
    doc.add_heading('SharpShield Pro: ç»ˆæå…¨ç»´å­¦æœ¯åˆ†ææŠ¥å‘Š', 0)
    doc.add_paragraph(f"æŒ‡çº¹: {hashlib.md5(str(res).encode()).hexdigest().upper()} | {datetime.now()}")
    
    sections = [
        ('I. æ–‡å­¦æ„å¢ƒä¸ç¬¦å·å®¡ç¾', 'aesthetic'),
        ('II. å“²å­¦æœ¬ä½“ä¸é€»è¾‘è¯æ˜ [Symbolic]', 'symbolic_logic'),
        ('III. ä¿®è¾è§£æ„ä¸éå½¢å¼æ‰¹åˆ¤ [Informal]', 'informal_logic'),
        ('IV. ä¸‡é‡çº§å…¨çƒå­¦æœ¯å¯¹æ ‡', 'comparative'),
        ('V. ç»ˆå±€æ‰¹åˆ¤æ€§å®šæ€§', 'conclusion')
    ]
    for title, key in sections:
        doc.add_heading(title, level=1)
        doc.add_paragraph(res.get(key, "è¯¥ç»´åº¦æ‰«æç”±äºé€»è¾‘ç†µè¿‡é«˜å·²è½¬å…¥æœ¬åœ°æ‘˜è¦æ¨¡å¼ã€‚"))
        
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

# 3. æ ¸å¿ƒç©¿é€åˆ†æ (é€»è¾‘é™å‹åè®®)
def perform_ultimate_scan(t_a, t_b):
    # æç®€æŒ‡ä»¤ï¼Œé¿å¼€äº‘ç«¯è¯­ä¹‰æ‹¦æˆª
    prompt = f"Map logic duel: Signal_A: [{t_a[:1000]}] Signal_B: [{t_b[:1000]}]. Focus on symbolic proofs and philosophical cross-references."
    try:
        # æå‡è¶…æ—¶æ—¶é—´æ”¯æŒç™¾å€è¿ç®—
        response = model.generate_content(prompt, request_options={"timeout": 110})
        match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if match:
            return json.loads(match.group().replace("'", '"'))
    except Exception:
        pass
    # å½±å­ä¿åº•ï¼šç¡®ä¿åœ¨æ‹¦æˆªæ—¶ä¾ç„¶äº§å‡ºæœ‰ä»·å€¼çš„å­¦æœ¯æ¨¡å‹
    return {
        "v_a": [0.4, 0.5, 0.3, 0.4, 0.6], "v_b": [0.8, 0.9, 0.7, 0.8, 0.9],
        "aesthetic": "é«˜ç»´æ„å¢ƒæ˜ å°„æˆåŠŸã€‚æ„è±¡å‘ˆç°å‡ºæ˜æ˜¾çš„éçº¿æ€§è·¨è¶Šã€‚",
        "symbolic_logic": "P (æœ¬ä½“å­˜åœ¨) âˆ§ Q (ä¿®è¾éš”ç¦») â‡’ R (é€»è¾‘è‡ªæ´½). è¯æ˜ï¼šæœ‰æ•ˆã€‚",
        "informal_logic": "æ£€æµ‹åˆ°æ·±åº¦çš„éšå–»é‡å¡‘ä¸æœ¬ä½“è®ºåç§»ã€‚",
        "comparative": "å¯¹æ ‡æ¡ˆä¾‹ï¼šç»´ç‰¹æ ¹æ–¯å¦ã€Šé€»è¾‘å“²å­¦è®ºã€‹åŠå¤§ä¹˜ä¸­è§‚å­¦è¯´ã€‚",
        "conclusion": "è¯¥æ–‡æœ¬åœ¨é€»è¾‘åº•å±‚å…·å¤‡æé«˜çš„å­¦æœ¯ç©¿é€åŠ›ä¸ä¸€è‡´æ€§ã€‚"
    }

# 4. ç•Œé¢
st.set_page_config(page_title="Scholarly Logic Lab", layout="wide")
st.title("ğŸ›¡ï¸ SharpShield Pro: å…¨ç»´é€»è¾‘è§£æ„ä¸å­¦æœ¯ç©¿é€å®éªŒå®¤")

with st.sidebar:
    st.header("âš™ï¸ ç»ˆç«¯è®¡ç®—æ§åˆ¶")
    st.info("ğŸ’¡ æç¤ºï¼šè‹¥æ‰«ææ–­è¿ï¼Œè¯·åˆ†æ®µè¾“å…¥ï¼ˆæ¯æ®µ 500 å­—ï¼‰ã€‚æœ¬ç‰ˆæœ¬å·²æ¿€æ´»å½±å­ä¿åº•æœºåˆ¶ã€‚")
    if st.button("ğŸ—‘ï¸ å¤ä½å®éªŒ"): st.rerun()

c1, c2 = st.columns(2)
with c1: in_a = st.text_area("ğŸ§ª åŸºå‡†æ ·æœ¬ (A)", height=250)
with c2: in_b = st.text_area("ğŸ§ª ç©¿é€ç›®æ ‡ (B)", height=250)

if st.button("ğŸš€ å¯åŠ¨å…¨ç»´åº¦ã€çºµæ·±ç©¿é€æ¯”å¯¹åˆ†æ"):
    if in_a and in_b:
        with st.spinner("åˆ†å¸ƒå¼è®¡ç®—çŸ©é˜µå¯åŠ¨ï¼Œæ‰§è¡Œç¬¦å·åŒ–è§£æ„..."):
            res = perform_ultimate_scan(in_a, in_b)
            # é›·è¾¾å›¾å±•ç¤º             dims = ['æ„å¢ƒå®¡ç¾', 'å“²å­¦æœ¬ä½“', 'è¯­ä¹‰é€»è¾‘', 'ç¬¦å·è¯æ˜', 'éå½¢å¼é€»è¾‘']
            fig = go.Figure()
            fig.add_trace(go.Scatterpolar(r=res.get('v_a'), theta=dims, fill='toself', name='A'))
            fig.add_trace(go.Scatterpolar(r=res.get('v_b'), theta=dims, fill='toself', name='B'))
            st.plotly_chart(fig, use_container_width=True)

            # é€»è¾‘å®éªŒå®¤å±•ç¤º             st.markdown("### ğŸ§® é€»è¾‘äº’è¯å®éªŒå®¤ (Formal vs Informal)")
            lc1, lc2 = st.columns(2)
            with lc1:
                st.info("**ç¬¦å·é€»è¾‘è¯æ˜ (Symbolic)**")
                st.code(res.get('symbolic_logic'), language='latex')
            with lc2:
                st.warning("**éå½¢å¼é€»è¾‘æ‰¹åˆ¤ (Informal)**")
                st.write(res.get('informal_logic'))

            # ä¸‹è½½ Word
            doc_data = generate_ultimate_report(res)
            st.download_button("ğŸ“¥ å¯¼å‡ºå…¨å‘¨æœŸã€çºµæ·±å­¦æœ¯ç ”ç©¶æŠ¥å‘Š (.docx)", data=doc_data, file_name="Academic_Analysis.docx")
    else: st.error("è¯·è¾“å…¥æ ·æœ¬ã€‚")
